{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fOY6MNepcUEX",
        "i1pIBZGzZxSA",
        "iAfUNG60aRD1"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aertist/ai/blob/main/StyleGAN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMdpKY1XODz2"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "!git clone https://github.com/dvschultz/stylegan2\n",
        "!pip install opensimplex # needed for noise interpolation\n",
        "%cd stylegan2\n",
        "%mkdir datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5xJGBg4bPmQ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9vCDt9LRtXl"
      },
      "source": [
        "#Test the model\n",
        "The following command will generate 55 sample images from the model.\n",
        "\n",
        "##Options\n",
        "`--network`\n",
        "\n",
        "Make sure the `--network` argument points to your .pkl file. (My preferred method is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that into the argument after the `=` sign).\n",
        "\n",
        "`--seeds`\n",
        "\n",
        "This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation.\n",
        "\n",
        "`--truncation-psi`\n",
        "\n",
        "Truncation is a special argument of StyleGAN. Essentially values that are closer to 0 will be more real than numbers further away from 0. I generally recommend a value between `0.5` and `1.0`. `0.5` will give you pretty \"realistic\" results, while `1.0` is likely to give you \"weirder\" results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTwJjmCrlfAc"
      },
      "source": [
        "#Interpolation (Creating Videos)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ2rYIC4TdaJ"
      },
      "source": [
        "!python run_generator.py generate-latent-walk --network /content/drive/MyDrive/Models/art.pkl --seeds 11,17,25,34,78,90,21,45,67,87,44,65,85,12,32,40,11 --frames 500 --truncation-psi=0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dceBSxTsmW1H"
      },
      "source": [
        "#convert to video \n",
        "!ffmpeg -r 25 -i ./results/00000-generate-latent-walk/frame%05d.png -vcodec libx264 -pix_fmt yuv420p output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMiqkA3IReZB"
      },
      "source": [
        "Letâ€™s zip the generated files and download them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp8O01O3PlFx"
      },
      "source": [
        "!zip -r interpolation_frames.zip /content/stylegan2/results/00000-generate-latent-walk "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOY6MNepcUEX"
      },
      "source": [
        "#To simply generate images from the dataset\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3MhXEAMOMXH"
      },
      "source": [
        "!python run_generator.py generate-images --network=/content/ladiesfloralcrop-network-snapshot-010237.pkl --seeds=3875451-3876000 --truncation-psi=0.7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAqXJ0aicjTe"
      },
      "source": [
        "!zip -r generated-0.7.zip /content/stylegan2/results/00000-generate-images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1pIBZGzZxSA"
      },
      "source": [
        "#Converting your dataset\n",
        "StyleGAN requires you to convert your standard jpg or png images into a new format (.tfrecords). I recommend doing this on your server because the files become quite large and will be slow to upload over FTP.\n",
        "\n",
        "After the `create_from_images` argument you need to pass in two paths. The first path is where the .tfrecords files should be output (just edit the last part to have a unique name). The second path is to the directory of your images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixjcx2-cbTDm"
      },
      "source": [
        "python dataset_tool.py create_from_images ./datasets/my-custom-dataset ./my-custom-images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ7U1ftuj_Dc"
      },
      "source": [
        "Once running, your training files will show up in the results folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAfUNG60aRD1"
      },
      "source": [
        "#Training\n",
        "I do not recommend attempting to train your model on Colab. It will be a very tedious process. Here are the steps, however.\n",
        "\n",
        "##Training Options\n",
        "`--dataset`\n",
        "\n",
        "This should be the name you used in the first path when converting your dataset.\n",
        "\n",
        "`--mirror-augment`\n",
        "\n",
        "Using this option loads some images at random mirrored horizontally (left-to-right). This might help if you have a very small dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QrOVqEHaipA"
      },
      "source": [
        "!python run_training.py --num-gpus=1 --data-dir=~/datasets --config=config-f --dataset=ffhq --mirror-augment=true"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
