{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleGAN2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvschultz/ai/blob/master/StyleGAN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMdpKY1XODz2",
        "colab_type": "code",
        "outputId": "08c689e4-68ea-4ff1-9fef-4c0c821f70ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "!git clone https://github.com/dvschultz/stylegan2\n",
        "!pip install opensimplex # needed for noise interpolation\n",
        "%cd stylegan2\n",
        "%mkdir datasets"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 215 (delta 0), reused 1 (delta 0), pack-reused 211\u001b[K\n",
            "Receiving objects: 100% (215/215), 15.25 MiB | 31.86 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n",
            "/content/stylegan2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1pIBZGzZxSA",
        "colab_type": "text"
      },
      "source": [
        "#Converting your dataset\n",
        "StyleGAN requires you to convert your standard jpg or png images into a new format (.tfrecords). I recommend doing this on your server because the files become quite large and will be slow to upload over FTP.\n",
        "\n",
        "After the `create_from_images` argument you need to pass in two paths. The first path is where the .tfrecords files should be output (just edit the last part to have a unique name). The second path is to the directory of your images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixjcx2-cbTDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "python dataset_tool.py create_from_images ./datasets/my-custom-dataset ./my-custom-images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAfUNG60aRD1",
        "colab_type": "text"
      },
      "source": [
        "#Training\n",
        "I do not recommend attempting to train your model on Colab. It will be a very tedious process. Here are the steps, however.\n",
        "\n",
        "##Training Options\n",
        "`--dataset`\n",
        "\n",
        "This should be the name you used in the first path when converting your dataset.\n",
        "\n",
        "`--mirror-augment`\n",
        "\n",
        "Using this option loads some images at random mirrored horizontally (left-to-right). This might help if you have a very small dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QrOVqEHaipA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python run_training.py --num-gpus=1 --data-dir=~/datasets --config=config-f --dataset=ffhq --mirror-augment=true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ7U1ftuj_Dc",
        "colab_type": "text"
      },
      "source": [
        "Once running, your training files will show up in the results folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9vCDt9LRtXl",
        "colab_type": "text"
      },
      "source": [
        "#Test the model\n",
        "The following command will generate 55 sample images from the model.\n",
        "\n",
        "##Options\n",
        "`--network`\n",
        "\n",
        "Make sure the `--network` argument points to your .pkl file. (My preferred method is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that into the argument after the `=` sign).\n",
        "\n",
        "`--seeds`\n",
        "\n",
        "This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation.\n",
        "\n",
        "`--truncation-psi`\n",
        "\n",
        "Truncation is a special argument of StyleGAN. Essentially values that are closer to 0 will be more real than numbers further away from 0. I generally recommend a value between `0.5` and `1.0`. `0.5` will give you pretty \"realistic\" results, while `1.0` is likely to give you \"weirder\" results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3MhXEAMOMXH",
        "colab_type": "code",
        "outputId": "537f4e6e-4150-4a73-efe8-9a593bda6de9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "!python run_generator.py generate-images --network=/content/ladiesfloralcrop-network-snapshot-010237.pkl --seeds=3875451-3876000 --truncation-psi=0.7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Local submit - run_dir: results/00000-generate-images\n",
            "dnnlib: Running run_generator.generate_images() on localhost...\n",
            "Loading networks from \"/content/ladiesfloralcrop-network-snapshot-010237.pkl\"...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Compiling... Loading... Done.\n",
            "Generating image for seed 1 (0/25) ...\n",
            "Generating image for seed 2 (1/25) ...\n",
            "Generating image for seed 3 (2/25) ...\n",
            "Generating image for seed 4 (3/25) ...\n",
            "Generating image for seed 5 (4/25) ...\n",
            "Generating image for seed 6 (5/25) ...\n",
            "Generating image for seed 7 (6/25) ...\n",
            "Generating image for seed 8 (7/25) ...\n",
            "Generating image for seed 9 (8/25) ...\n",
            "Generating image for seed 10 (9/25) ...\n",
            "Generating image for seed 11 (10/25) ...\n",
            "Generating image for seed 12 (11/25) ...\n",
            "Generating image for seed 13 (12/25) ...\n",
            "Generating image for seed 14 (13/25) ...\n",
            "Generating image for seed 15 (14/25) ...\n",
            "Generating image for seed 16 (15/25) ...\n",
            "Generating image for seed 17 (16/25) ...\n",
            "Generating image for seed 18 (17/25) ...\n",
            "Generating image for seed 19 (18/25) ...\n",
            "Generating image for seed 20 (19/25) ...\n",
            "Generating image for seed 21 (20/25) ...\n",
            "Generating image for seed 22 (21/25) ...\n",
            "Generating image for seed 23 (22/25) ...\n",
            "Generating image for seed 24 (23/25) ...\n",
            "Generating image for seed 25 (24/25) ...\n",
            "dnnlib: Finished run_generator.generate_images() in 1m 19s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMiqkA3IReZB",
        "colab_type": "text"
      },
      "source": [
        "Letâ€™s zip the generated files and download them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp8O01O3PlFx",
        "colab_type": "code",
        "outputId": "e9e84d6d-1523-4283-af1e-11299a014c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "!zip -r generated-0.7.zip /content/stylegan2/results/00000-generate-images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/stylegan2/results/00000-generate-images/ (stored 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0025.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0014.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0007.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0018.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0017.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0010.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0015.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0024.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0021.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0004.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/log.txt (deflated 74%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0012.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0009.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0022.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0013.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0011.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0008.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0002.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0001.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/submit_config.txt (deflated 53%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/submit_config.pkl (deflated 43%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0019.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0016.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/run.txt (deflated 34%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0006.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0005.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/_finished.txt (stored 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0023.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0020.png (deflated 0%)\n",
            "  adding: content/stylegan2/results/00000-generate-images/seed0003.png (deflated 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTwJjmCrlfAc",
        "colab_type": "text"
      },
      "source": [
        "#Interpolation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ2rYIC4TdaJ",
        "colab_type": "code",
        "outputId": "889a6ced-d1bc-421f-8d71-a6afedd5310c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_generator.py generate-latent-walk --network=/content/ladiesfloralcrop-network-snapshot-010237.pkl --seeds=3,11,17,25,3 --frames 200 --truncation-psi=0.7"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Local submit - run_dir: results/00002-generate-latent-walk\n",
            "dnnlib: Running run_generator.generate_latent_walk() on localhost...\n",
            "Loading networks from \"/content/ladiesfloralcrop-network-snapshot-010237.pkl\"...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n",
            "Generating image for step 0/204 ...\n",
            "Generating image for step 1/204 ...\n",
            "Generating image for step 2/204 ...\n",
            "Generating image for step 3/204 ...\n",
            "Generating image for step 4/204 ...\n",
            "Generating image for step 5/204 ...\n",
            "Generating image for step 6/204 ...\n",
            "Generating image for step 7/204 ...\n",
            "Generating image for step 8/204 ...\n",
            "Generating image for step 9/204 ...\n",
            "Generating image for step 10/204 ...\n",
            "Generating image for step 11/204 ...\n",
            "Generating image for step 12/204 ...\n",
            "Generating image for step 13/204 ...\n",
            "Generating image for step 14/204 ...\n",
            "Generating image for step 15/204 ...\n",
            "Generating image for step 16/204 ...\n",
            "Generating image for step 17/204 ...\n",
            "Generating image for step 18/204 ...\n",
            "Generating image for step 19/204 ...\n",
            "Generating image for step 20/204 ...\n",
            "Generating image for step 21/204 ...\n",
            "Generating image for step 22/204 ...\n",
            "Generating image for step 23/204 ...\n",
            "Generating image for step 24/204 ...\n",
            "Generating image for step 25/204 ...\n",
            "Generating image for step 26/204 ...\n",
            "Generating image for step 27/204 ...\n",
            "Generating image for step 28/204 ...\n",
            "Generating image for step 29/204 ...\n",
            "Generating image for step 30/204 ...\n",
            "Generating image for step 31/204 ...\n",
            "Generating image for step 32/204 ...\n",
            "Generating image for step 33/204 ...\n",
            "Generating image for step 34/204 ...\n",
            "Generating image for step 35/204 ...\n",
            "Generating image for step 36/204 ...\n",
            "Generating image for step 37/204 ...\n",
            "Generating image for step 38/204 ...\n",
            "Generating image for step 39/204 ...\n",
            "Generating image for step 40/204 ...\n",
            "Generating image for step 41/204 ...\n",
            "Generating image for step 42/204 ...\n",
            "Generating image for step 43/204 ...\n",
            "Generating image for step 44/204 ...\n",
            "Generating image for step 45/204 ...\n",
            "Generating image for step 46/204 ...\n",
            "Generating image for step 47/204 ...\n",
            "Generating image for step 48/204 ...\n",
            "Generating image for step 49/204 ...\n",
            "Generating image for step 50/204 ...\n",
            "Generating image for step 51/204 ...\n",
            "Generating image for step 52/204 ...\n",
            "Generating image for step 53/204 ...\n",
            "Generating image for step 54/204 ...\n",
            "Generating image for step 55/204 ...\n",
            "Generating image for step 56/204 ...\n",
            "Generating image for step 57/204 ...\n",
            "Generating image for step 58/204 ...\n",
            "Generating image for step 59/204 ...\n",
            "Generating image for step 60/204 ...\n",
            "Generating image for step 61/204 ...\n",
            "Generating image for step 62/204 ...\n",
            "Generating image for step 63/204 ...\n",
            "Generating image for step 64/204 ...\n",
            "Generating image for step 65/204 ...\n",
            "Generating image for step 66/204 ...\n",
            "Generating image for step 67/204 ...\n",
            "Generating image for step 68/204 ...\n",
            "Generating image for step 69/204 ...\n",
            "Generating image for step 70/204 ...\n",
            "Generating image for step 71/204 ...\n",
            "Generating image for step 72/204 ...\n",
            "Generating image for step 73/204 ...\n",
            "Generating image for step 74/204 ...\n",
            "Generating image for step 75/204 ...\n",
            "Generating image for step 76/204 ...\n",
            "Generating image for step 77/204 ...\n",
            "Generating image for step 78/204 ...\n",
            "Generating image for step 79/204 ...\n",
            "Generating image for step 80/204 ...\n",
            "Generating image for step 81/204 ...\n",
            "Generating image for step 82/204 ...\n",
            "Generating image for step 83/204 ...\n",
            "Generating image for step 84/204 ...\n",
            "Generating image for step 85/204 ...\n",
            "Generating image for step 86/204 ...\n",
            "Generating image for step 87/204 ...\n",
            "Generating image for step 88/204 ...\n",
            "Generating image for step 89/204 ...\n",
            "Generating image for step 90/204 ...\n",
            "Generating image for step 91/204 ...\n",
            "Generating image for step 92/204 ...\n",
            "Generating image for step 93/204 ...\n",
            "Generating image for step 94/204 ...\n",
            "Generating image for step 95/204 ...\n",
            "Generating image for step 96/204 ...\n",
            "Generating image for step 97/204 ...\n",
            "Generating image for step 98/204 ...\n",
            "Generating image for step 99/204 ...\n",
            "Generating image for step 100/204 ...\n",
            "Generating image for step 101/204 ...\n",
            "Generating image for step 102/204 ...\n",
            "Generating image for step 103/204 ...\n",
            "Generating image for step 104/204 ...\n",
            "Generating image for step 105/204 ...\n",
            "Generating image for step 106/204 ...\n",
            "Generating image for step 107/204 ...\n",
            "Generating image for step 108/204 ...\n",
            "Generating image for step 109/204 ...\n",
            "Generating image for step 110/204 ...\n",
            "Generating image for step 111/204 ...\n",
            "Generating image for step 112/204 ...\n",
            "Generating image for step 113/204 ...\n",
            "Generating image for step 114/204 ...\n",
            "Generating image for step 115/204 ...\n",
            "Generating image for step 116/204 ...\n",
            "Generating image for step 117/204 ...\n",
            "Generating image for step 118/204 ...\n",
            "Generating image for step 119/204 ...\n",
            "Generating image for step 120/204 ...\n",
            "Generating image for step 121/204 ...\n",
            "Generating image for step 122/204 ...\n",
            "Generating image for step 123/204 ...\n",
            "Generating image for step 124/204 ...\n",
            "Generating image for step 125/204 ...\n",
            "Generating image for step 126/204 ...\n",
            "Generating image for step 127/204 ...\n",
            "Generating image for step 128/204 ...\n",
            "Generating image for step 129/204 ...\n",
            "Generating image for step 130/204 ...\n",
            "Generating image for step 131/204 ...\n",
            "Generating image for step 132/204 ...\n",
            "Generating image for step 133/204 ...\n",
            "Generating image for step 134/204 ...\n",
            "Generating image for step 135/204 ...\n",
            "Generating image for step 136/204 ...\n",
            "Generating image for step 137/204 ...\n",
            "Generating image for step 138/204 ...\n",
            "Generating image for step 139/204 ...\n",
            "Generating image for step 140/204 ...\n",
            "Generating image for step 141/204 ...\n",
            "Generating image for step 142/204 ...\n",
            "Generating image for step 143/204 ...\n",
            "Generating image for step 144/204 ...\n",
            "Generating image for step 145/204 ...\n",
            "Generating image for step 146/204 ...\n",
            "Generating image for step 147/204 ...\n",
            "Generating image for step 148/204 ...\n",
            "Generating image for step 149/204 ...\n",
            "Generating image for step 150/204 ...\n",
            "Generating image for step 151/204 ...\n",
            "Generating image for step 152/204 ...\n",
            "Generating image for step 153/204 ...\n",
            "Generating image for step 154/204 ...\n",
            "Generating image for step 155/204 ...\n",
            "Generating image for step 156/204 ...\n",
            "Generating image for step 157/204 ...\n",
            "Generating image for step 158/204 ...\n",
            "Generating image for step 159/204 ...\n",
            "Generating image for step 160/204 ...\n",
            "Generating image for step 161/204 ...\n",
            "Generating image for step 162/204 ...\n",
            "Generating image for step 163/204 ...\n",
            "Generating image for step 164/204 ...\n",
            "Generating image for step 165/204 ...\n",
            "Generating image for step 166/204 ...\n",
            "Generating image for step 167/204 ...\n",
            "Generating image for step 168/204 ...\n",
            "Generating image for step 169/204 ...\n",
            "Generating image for step 170/204 ...\n",
            "Generating image for step 171/204 ...\n",
            "Generating image for step 172/204 ...\n",
            "Generating image for step 173/204 ...\n",
            "Generating image for step 174/204 ...\n",
            "Generating image for step 175/204 ...\n",
            "Generating image for step 176/204 ...\n",
            "Generating image for step 177/204 ...\n",
            "Generating image for step 178/204 ...\n",
            "Generating image for step 179/204 ...\n",
            "Generating image for step 180/204 ...\n",
            "Generating image for step 181/204 ...\n",
            "Generating image for step 182/204 ...\n",
            "Generating image for step 183/204 ...\n",
            "Generating image for step 184/204 ...\n",
            "Generating image for step 185/204 ...\n",
            "Generating image for step 186/204 ...\n",
            "Generating image for step 187/204 ...\n",
            "Generating image for step 188/204 ...\n",
            "Generating image for step 189/204 ...\n",
            "Generating image for step 190/204 ...\n",
            "Generating image for step 191/204 ...\n",
            "Generating image for step 192/204 ...\n",
            "Generating image for step 193/204 ...\n",
            "Generating image for step 194/204 ...\n",
            "Generating image for step 195/204 ...\n",
            "Generating image for step 196/204 ...\n",
            "Generating image for step 197/204 ...\n",
            "Generating image for step 198/204 ...\n",
            "Generating image for step 199/204 ...\n",
            "Generating image for step 200/204 ...\n",
            "Generating image for step 201/204 ...\n",
            "Generating image for step 202/204 ...\n",
            "Generating image for step 203/204 ...\n",
            "dnnlib: Finished run_generator.generate_latent_walk() in 2m 20s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dceBSxTsmW1H",
        "colab_type": "code",
        "outputId": "3e7f602e-8ec4-461d-ab6c-5aee753fff83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "#convert to video \n",
        "!ffmpeg -r 24 -i ./results/00001-generate-latent-walk/step%05d.png -vcodec libx264 -pix_fmt yuv420p latent-walk-v2.mp4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from './results/00001-generate-latent-walk/step%05d.png':\n",
            "  Duration: 00:00:08.16, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 1024x1024, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mprofile High, level 3.2\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'latent-walk-v2.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1024x1024, q=-1--1, 24 fps, 12288 tbn, 24 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "frame=  204 fps=7.7 q=-1.0 Lsize=   12124kB time=00:00:08.37 bitrate=11859.2kbits/s speed=0.315x    \n",
            "video:12121kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.024653%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mframe I:1     Avg QP:27.07  size:147205\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mframe P:93    Avg QP:27.89  size: 81048\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mframe B:110   Avg QP:30.42  size: 42971\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mconsecutive B-frames: 27.5%  2.0%  0.0% 70.6%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mmb I  I16..4:  8.6% 57.3% 34.2%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mmb P  I16..4:  0.6% 15.3%  8.5%  P16..4: 32.1% 22.5% 15.4%  0.0%  0.0%    skip: 5.6%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mmb B  I16..4:  0.1%  2.7%  2.8%  B16..8: 27.2% 16.2%  8.5%  direct:17.4%  skip:25.2%  L0:29.0% L1:34.5% BI:36.5%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0m8x8 transform intra:59.7% inter:56.9%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mcoded y,uvDC,uvAC intra: 88.8% 83.9% 51.5% inter: 53.3% 28.1% 1.7%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mi16 v,h,dc,p: 43% 22% 21% 14%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 16% 11% 12%  8% 11% 12% 10% 11% 10%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 12% 13%  7% 13% 12% 11%  9%  7%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mi8c dc,h,v,p: 52% 18% 21%  9%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mWeighted P-Frames: Y:19.4% UV:14.0%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mref P L0: 64.4% 26.9%  6.1%  2.0%  0.5%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mref B L0: 95.6%  3.3%  1.1%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mref B L1: 99.1%  0.9%\n",
            "\u001b[1;36m[libx264 @ 0x55a800235e00] \u001b[0mkb/s:11681.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7A7jRRGmzhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}